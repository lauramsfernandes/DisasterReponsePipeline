{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600693695253",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\laura\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Unzipping tokenizers\\punkt.zip.\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\laura\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "source": [
    "# Pipeline\n",
    "\n",
    "Data pipeline is a generic term for transfering data from one or more sources to a destination.\n",
    "\n",
    "## ETL\n",
    "\n",
    "A ETL pipeline is a procedure that `extract` data from a source or multiple sources, `transform` the data according with the project specifications and `load` the data to its destination. \n",
    "\n",
    "> Extract data -> Tansform data -> Load data into database -> Create an ETL pipeline\n",
    "\n",
    "## ELT \n",
    "\n",
    "A ELT pipeline differs from ETL in order of processes. In ELT the load are done previously than transformation.\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Extracting data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting corporate messaging data as dataframe\n",
    "df = pd.read_csv(r'data\\corporate_messaging.csv')"
   ]
  },
  {
   "source": [
    "### Wrangling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n0  662822308    False   finalized                   3      2/18/15 4:31   \n1  662822309    False   finalized                   3     2/18/15 13:55   \n\n      category  category:confidence category_gold            id screenname  \\\n0  Information                  1.0           NaN  4.365280e+17   Barclays   \n1  Information                  1.0           NaN  3.860130e+17   Barclays   \n\n                                                text  \n0  Barclays CEO stresses the importance of regula...  \n1  Barclays announces result of Rights Issue http...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_unit_id</th>\n      <th>_golden</th>\n      <th>_unit_state</th>\n      <th>_trusted_judgments</th>\n      <th>_last_judgment_at</th>\n      <th>category</th>\n      <th>category:confidence</th>\n      <th>category_gold</th>\n      <th>id</th>\n      <th>screenname</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>662822308</td>\n      <td>False</td>\n      <td>finalized</td>\n      <td>3</td>\n      <td>2/18/15 4:31</td>\n      <td>Information</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4.365280e+17</td>\n      <td>Barclays</td>\n      <td>Barclays CEO stresses the importance of regula...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>662822309</td>\n      <td>False</td>\n      <td>finalized</td>\n      <td>3</td>\n      <td>2/18/15 13:55</td>\n      <td>Information</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>3.860130e+17</td>\n      <td>Barclays</td>\n      <td>Barclays announces result of Rights Issue http...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "# Checking df\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "df has 3118 rows and 11 columns\n"
    }
   ],
   "source": [
    "# Checking initial shape\n",
    "rows, columns = df.shape\n",
    "print('df has {} rows and {} columns'.format(rows, columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "_unit_id               0.000000\n_golden                0.000000\n_unit_state            0.000000\n_trusted_judgments     0.000000\n_last_judgment_at      0.088223\ncategory               0.000000\ncategory:confidence    0.000000\ncategory_gold          0.911777\nid                     0.000000\nscreenname             0.000000\ntext                   0.000000\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "# Checking nulls ratio\n",
    "df.isnull().sum()/rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n       '_last_judgment_at', 'category', 'category:confidence', 'category_gold',\n       'id', 'screenname', 'text'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "# Checking columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0       Barclays CEO stresses the importance of regula...\n1       Barclays announces result of Rights Issue http...\n2       Barclays publishes its prospectus for its å£5....\n3       Barclays Group Finance Director Chris Lucas is...\n4       Barclays announces that Irene McDermott Brown ...\n                              ...                        \n3107    We're grateful for 2x honors @ChamberBCLC Citi...\n3108    WeÌ¢‰âÂ‰ã¢re the 1. to sign up to a European i...\n3109    WeÌ¢‰âÂ‰ã¢re working hard to do all we can to ...\n3115    Yesterday, these #HealthyKids lit up Broadway ...\n3117    Z Bhutta: Problems with food&amp;land systems ...\nName: text, Length: 2403, dtype: object"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "# Checking text columns values\n",
    "df.loc[:,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.0000    2430\n0.6614      35\n0.6643      33\n0.6747      32\n0.6775      29\n          ... \n0.8547       1\n0.6641       1\n0.8578       1\n0.9089       1\n0.8245       1\nName: category:confidence, Length: 194, dtype: int64"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# Checking category confidence values\n",
    "df.loc[:,'category:confidence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Information    2129\nAction          724\nDialogue        226\nExclude          39\nName: category, dtype: int64"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "# Checking categories\n",
    "df.loc[:,'category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only with messages that have confidence equal to 1 and the category is different from 'Exclude'\n",
    "df = df[(df.loc[:,'category:confidence']==1) & (df.loc[:,'category'] != 'Exclude')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "df now has 2403 rows and 11 columns\n"
    }
   ],
   "source": [
    "# Checking new shape\n",
    "rows, columns = df.shape\n",
    "print('df now has {} rows and {} columns'.format(rows, columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenization Function\n",
    "def tokenize(text):\n",
    "    \"\"\" \n",
    "    DESCRIPTION\n",
    "    1. Dectect all urls in each message, replace all of them for a string.\n",
    "    2. Tokenize: delimit all words in each message.\n",
    "    3. Lemmatize: group together the inflected forms of a word, so they can be analysed as a single item, identified them by the word's lemma.\n",
    "\n",
    "    INPUT\n",
    "    text (string): a string of disaster messages.\n",
    "\n",
    "    OUTPUT\n",
    "    clean_tokens (string): a tokenized list from input.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1.\n",
    "    # Dectect url using regex\n",
    "    url = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    detected_urls = re.findall(url,text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, 'urlplaceholder')\n",
    "\n",
    "    # 2.\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # 3.\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = []\n",
    "    for token in tokens:\n",
    "        # take each word on tokens list and lemmatize.\n",
    "        clean_token = lemmatizer.lemmatize(token)\n",
    "        # add clean token into the clean_tokens list\n",
    "        clean_tokens.append(clean_token)\n",
    "\n",
    "    return clean_tokens\n"
   ]
  },
  {
   "source": [
    "### Train and Test Split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data for test\n",
    "X = df.text.values\n",
    "y = df.category.values\n",
    "\n",
    "# Training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_results(y_test, y_pred):\n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\laura\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\laura\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nLabels: ['Action' 'Dialogue' 'Information']\nConfusion Matrix:\n [[ 96   1  31]\n [  0  27   8]\n [  4   1 433]]\nAccuracy: 0.9251247920133111\n"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(r'data\\corporate_messaging.csv')\n",
    "    df = df[(df[\"category:confidence\"] == 1) & (df['category'] != 'Exclude')]\n",
    "    X = df.text.values\n",
    "    y = df.category.values\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens\n",
    "\n",
    "\n",
    "def display_results(y_test, y_pred):\n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "def main():\n",
    "    X, y = load_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    vect = CountVectorizer(tokenizer=tokenize)\n",
    "    tfidf = TfidfTransformer()\n",
    "    clf = RandomForestClassifier()\n",
    "\n",
    "    # train classifier\n",
    "    X_train_counts = vect.fit_transform(X_train)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train_counts)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # predict on test data\n",
    "    X_test_counts = vect.transform(X_test)\n",
    "    X_test_tfidf = tfidf.transform(X_test_counts)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "    # display results\n",
    "    display_results(y_test, y_pred)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}